{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9b9266f-a14c-4c45-8d07-9a440210370b",
   "metadata": {},
   "source": [
    "# FELIPE AVILES ALEJANDRO - 2020330348"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1452dae-00bd-4336-b466-9eac5cd2127d",
   "metadata": {},
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b80f3e23-d3a8-4f5f-b9b9-9f1994547fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2992/1791803331.py:40: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(x[0]**2) + 2*np.exp(x[1]**2)*x[0]**2 + 4*x[0]*x[1] + 2*x[0]**2 + 4*x[0] - 2*x[1]\n",
      "/tmp/ipykernel_2992/1791803331.py:30: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  rho = 1 / np.dot(y.T, s)\n",
      "/tmp/ipykernel_2992/1791803331.py:31: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  H = (np.eye(len(x)) - rho * np.dot(s, y.T)).dot(H).dot(np.eye(len(x)) - rho * np.dot(y, s.T)) + rho * np.dot(s, s.T)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Punto mínimo: [nan nan]\n",
      "Valor mínimo: nan\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def quasi_newton(f, grad_f, x0, H0, tol=1e-6, maxiter=100):\n",
    "    \"\"\"\n",
    "    Método de Quasi-Newton para encontrar el mínimo de una función.\n",
    "\n",
    "    Parámetros:\n",
    "    f: función a minimizar.\n",
    "    grad_f: gradiente de la función a minimizar.\n",
    "    x0: punto inicial.\n",
    "    H0: matriz de aproximación inicial para la inversa de la hessiana.\n",
    "    tol: tolerancia de convergencia.\n",
    "    maxiter: número máximo de iteraciones.\n",
    "\n",
    "    Retorna:\n",
    "    x_min: punto que minimiza la función.\n",
    "    \"\"\"\n",
    "    x = x0\n",
    "    H = H0\n",
    "    k = 0\n",
    "    rk_norm = np.linalg.norm(grad_f(x))\n",
    "    while rk_norm > tol and k < maxiter:\n",
    "        p = -np.dot(H, grad_f(x))\n",
    "        alpha = 1\n",
    "        while f(x + alpha*p) > f(x) + 0.1*alpha*np.dot(grad_f(x).T, p):\n",
    "            alpha = alpha/2\n",
    "        s = alpha*p\n",
    "        x_next = x + s\n",
    "        y = grad_f(x_next) - grad_f(x)\n",
    "        rho = 1 / np.dot(y.T, s)\n",
    "        H = (np.eye(len(x)) - rho * np.dot(s, y.T)).dot(H).dot(np.eye(len(x)) - rho * np.dot(y, s.T)) + rho * np.dot(s, s.T)\n",
    "        x = x_next\n",
    "        rk_norm = np.linalg.norm(grad_f(x))\n",
    "        k += 1\n",
    "    x_min = x\n",
    "    return x_min\n",
    "\n",
    "# Función y gradiente\n",
    "def f(x):\n",
    "    return np.exp(x[0]**2) + 2*np.exp(x[1]**2)*x[0]**2 + 4*x[0]*x[1] + 2*x[0]**2 + 4*x[0] - 2*x[1]\n",
    "\n",
    "def grad_f(x):\n",
    "    return np.array([2*x[0]*np.exp(x[0]**2) + 4*np.exp(x[1]**2)*x[0] + 4*x[0] + 4,\n",
    "                     4*x[1]*np.exp(x[1]**2) + 4*np.exp(x[1]**2)*x[0] - 2])\n",
    "\n",
    "# Punto de partida y matriz de aproximación inicial para la inversa de la hessiana\n",
    "x0 = np.array([-1.8, 1.3])\n",
    "H0 = np.eye(len(x0))\n",
    "\n",
    "# Ejecutar el método\n",
    "x_min = quasi_newton(f, grad_f, x0, H0)\n",
    "\n",
    "# Imprimir resultado\n",
    "print(\"Punto mínimo:\", x_min)\n",
    "print(\"Valor mínimo:\", f(x_min))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473ef975-0dad-4cf8-ad1c-31ea444ca33b",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65b383f9-febd-486a-80b1-4e03f765ef01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Punto mínimo: [-0.1085217   2.02341719]\n",
      "Valor mínimo: -2.9108042881360623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2992/3835070628.py:5: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(x[0]**2) + 2*np.exp(x[1]**2)*x[0]**2 + 4*x[0]*x[1] + 2*x[0]**2 + 4*x[0] - 2*x[1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import approx_fprime\n",
    "\n",
    "def f(x):\n",
    "    return np.exp(x[0]**2) + 2*np.exp(x[1]**2)*x[0]**2 + 4*x[0]*x[1] + 2*x[0]**2 + 4*x[0] - 2*x[1]\n",
    "\n",
    "def grad_f(x):\n",
    "    return approx_fprime(x, f, epsilon=1e-6)\n",
    "\n",
    "\n",
    "\n",
    "def newton_method(f, grad_f, x0, tol=1e-6, maxiter=100):\n",
    "    x = x0\n",
    "    for i in range(maxiter):\n",
    "        # Calcular la dirección de descenso\n",
    "        H = np.array([[2*np.exp(x[0]**2) + 4*x[0]**2 + 4, 8*x[0]*np.exp(x[1]**2) + 4*x[1] + 4],\n",
    "                      [8*x[0]*np.exp(x[1]**2) + 4*x[1] + 4, 4*np.exp(x[1]**2)]])\n",
    "        g = grad_f(x)\n",
    "        d = -np.linalg.solve(H, g)\n",
    "        \n",
    "        # Calcular el tamaño del paso\n",
    "        alpha = 1.0\n",
    "        while f(x + alpha*d) > f(x):\n",
    "            alpha /= 2.0\n",
    "        \n",
    "        # Actualizar la solución\n",
    "        x_new = x + alpha*d\n",
    "        \n",
    "        # Comprobar la convergencia\n",
    "        if np.linalg.norm(x_new - x) < tol:\n",
    "            break\n",
    "        \n",
    "        x = x_new\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "x0 = np.array([-1.8, 1.3])\n",
    "x_min = newton_method(f, grad_f, x0)\n",
    "\n",
    "print(\"Punto mínimo:\", x_min)\n",
    "print(\"Valor mínimo:\", f(x_min))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c4296a-fb2b-44a8-87c8-bf09103cc205",
   "metadata": {},
   "source": [
    "# 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "03c6ab59-91a1-4691-991a-9522ca66f597",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a349bb86-88b3-4655-afb7-0f390da7c639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Punto mínimo: [[ 0.98237885 -0.07048458]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def conjugate_gradient(A, b, x0, tol=1e-5, maxiter=1000):\n",
    "    x = x0.copy()\n",
    "    residual = b - np.dot(A, x)\n",
    "    p = residual\n",
    "    k = 0\n",
    "    while np.linalg.norm(residual) > tol and k < maxiter:\n",
    "        Ap = np.dot(A, p)\n",
    "        alpha = np.dot(residual.T, residual) / np.dot(np.dot(p.T, A), p)\n",
    "        x = x + alpha * p\n",
    "        residual_new = residual - alpha * Ap\n",
    "        beta = np.dot(residual_new.T, residual_new) / np.dot(residual.T, residual)\n",
    "        p = residual_new + beta * p\n",
    "        residual = residual_new\n",
    "        k += 1\n",
    "    return x\n",
    "\n",
    "# Definir la matriz A y el vector b\n",
    "A = np.array([[-8, 2], [2, -114]])\n",
    "b = np.array([[-8], [10]])\n",
    "\n",
    "# Definir el punto de inicio x0\n",
    "x0 = np.array([[2], [-5]])\n",
    "\n",
    "x_min = conjugate_gradient(A, b, x0)\n",
    "\n",
    "print(\"Punto mínimo:\", x_min.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cd80fa3-564c-4e2b-b2dc-1b8b7929ef7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Punto crítico: (6.08160, -98.64864)\n",
      "Valor de la función objetivo: -558283.47397\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def objective(x, y):\n",
    "    return -4*x**2 - 57*y**2 + 4*x*y - 8*x + 10*y - 2\n",
    "\n",
    "def gradient(x, y):\n",
    "    dx = -8*x + 4*y - 8\n",
    "    dy = -114*y + 4*x + 10\n",
    "    return np.array([dx, dy])\n",
    "\n",
    "def search_direction(x, y, prev_direction, prev_gradient):\n",
    "    curr_gradient = gradient(x, y)\n",
    "    if np.all(curr_gradient == 0):\n",
    "        return prev_direction, curr_gradient\n",
    "    beta = np.dot(curr_gradient, curr_gradient - prev_gradient) / np.dot(prev_gradient, prev_gradient)\n",
    "    direction = -curr_gradient + beta * prev_direction\n",
    "    if np.all(direction == 0):\n",
    "        return direction, curr_gradient\n",
    "    return direction, curr_gradient\n",
    "\n",
    "alpha = 0.001  # Tamaño de paso\n",
    "x, y = 2/50, -5/50 # Normalizamos los valores iniciales\n",
    "direction = -gradient(x, y)\n",
    "iteration = 0\n",
    "precision = 0.00001\n",
    "max_iterations = 10000\n",
    "\n",
    "while np.linalg.norm(gradient(x, y)) > precision and iteration < max_iterations:\n",
    "    direction, prev_gradient = search_direction(x, y, direction, gradient(x, y))\n",
    "    x += alpha * direction[0]\n",
    "    y += alpha * direction[1]\n",
    "    iteration += 1\n",
    "\n",
    "    # Si x o y son demasiado grandes, normalizamos nuevamente los valores\n",
    "    if abs(x) > 100 or abs(y) > 100:\n",
    "        x /= 100\n",
    "        y /= 100\n",
    "        alpha /= 10\n",
    "\n",
    "x *= 50 # Desnormalizamos el valor de x\n",
    "y *= 50 # Desnormalizamos el valor de y\n",
    "\n",
    "print(\"Punto crítico: ({:.5f}, {:.5f})\".format(x, y))\n",
    "print(\"Valor de la función objetivo: {:.5f}\".format(objective(x, y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e006910-bec3-4f19-8201-50216561de99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Punto mínimo: [[ 0.98237885 -0.07048458]]\n"
     ]
    }
   ],
   "source": [
    "def conjugate_directions(f, grad_f, x0, directions, tol=1e-6, maxiter=1000):\n",
    "    \"\"\"\n",
    "    Encuentra el mínimo de la función `f` utilizando el método de direcciones conjugadas\n",
    "    con una base de direcciones dadas.\n",
    "    \n",
    "    Parámetros:\n",
    "    - f: la función a minimizar.\n",
    "    - grad_f: la función gradiente de `f`.\n",
    "    - x0: punto de partida para el algoritmo.\n",
    "    - directions: matriz de direcciones conjugadas a utilizar en el método.\n",
    "    - tol: tolerancia para la convergencia del algoritmo.\n",
    "    - maxiter: número máximo de iteraciones permitidas.\n",
    "    \n",
    "    Retorna:\n",
    "    - x_min: el punto que minimiza la función `f`.\n",
    "    \"\"\"\n",
    "    x = x0\n",
    "    residual = grad_f(x)\n",
    "    k = 0\n",
    "    d = directions[:,:,0]\n",
    "    delta = np.dot(d.T, np.dot(f(x), d))\n",
    "    \n",
    "    while np.linalg.norm(residual) > tol and k < maxiter:\n",
    "        alpha = np.dot(residual.T, residual) / delta\n",
    "        x = x + alpha * d\n",
    "        prev_residual = residual\n",
    "        residual = grad_f(x)\n",
    "        beta = np.dot(residual.T, np.dot(f(x), d)) / delta\n",
    "        d = residual - beta * d\n",
    "        delta = np.dot(d.T, np.dot(f(x), d))\n",
    "        k += 1\n",
    "    \n",
    "    return x\n",
    "\n",
    "print(\"Punto mínimo:\", x_min.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3f6a252-241e-4fbe-ab5a-a748669db244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Método de Newton:\n",
      "Punto mínimo: [-2.76237204  7.16226719]\n",
      "Valor mínimo: 2.897768130804401e+23\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Función objetivo\n",
    "def f(x):\n",
    "    return np.exp(x[0]**2) + 2*np.exp(x[1]**2)*x[0]**2 + 4*x[0]*x[1] + 2*x[0]**2 + 4*x[0] - 2*x[1]\n",
    "\n",
    "# Gradiente de la función objetivo\n",
    "def grad_f(x):\n",
    "    return np.array([2*x[0]*np.exp(x[0]**2) + 4*np.exp(x[1]**2)*x[0] + 4*x[1] + 4*x[0] - 2,\n",
    "                     4*x[0]*np.exp(x[1]**2) + 4*x[1] - 2*np.exp(x[1]**2)])\n",
    "\n",
    "# Hessiano de la función objetivo\n",
    "def hess_f(x):\n",
    "    return np.array([[4*np.exp(x[0]**2) + 8*x[0]**2*np.exp(x[0]**2) + 4*np.exp(x[1]**2),\n",
    "                      8*x[0]*x[1]*np.exp(x[0]**2 + x[1]**2) + 4*x[0]*np.exp(x[1]**2)],\n",
    "                     [8*x[0]*x[1]*np.exp(x[0]**2 + x[1]**2) + 4*x[0]*np.exp(x[1]**2),\n",
    "                      4*x[0]**2*np.exp(x[1]**2) + 16*np.exp(x[1]**2) - 4*np.exp(x[1]**2)]])\n",
    "\n",
    "# Método de Newton\n",
    "def newton_method(f, grad_f, hess_f, x0, tol=1e-6, maxiter=100):\n",
    "    x = x0\n",
    "    for i in range(maxiter):\n",
    "        grad = grad_f(x)\n",
    "        hess = hess_f(x)\n",
    "        d = np.linalg.solve(hess, -grad)\n",
    "        x = x + d\n",
    "        if np.linalg.norm(grad) < tol:\n",
    "            break\n",
    "    return x\n",
    "\n",
    "# Método de BFGS\n",
    "def bfgs_method(f, grad_f, x0, tol=1e-6, maxiter=100):\n",
    "    x = x0\n",
    "    H = np.eye(len(x))\n",
    "    for i in range(maxiter):\n",
    "        grad = grad_f(x)\n",
    "        d = -np.dot(H, grad)\n",
    "        alpha = minimize(lambda a: f(x + a*d), 0).x[0]\n",
    "        s = alpha * d\n",
    "        x_new = x + s\n",
    "        y = grad_f(x_new) - grad\n",
    "        rho = 1 / np.dot(y, s)\n",
    "        H_new = (np.eye(len(x)) - rho*np.outer(s, y)) @ H @ (np.eye(len(x)) - rho*np.outer(y, s)) + rho*np.outer(s, s)\n",
    "        x, H = x_new, H_new\n",
    "        if np.linalg.norm(s) < tol:\n",
    "            break\n",
    "    return x\n",
    "\n",
    "# Ejemplo de uso\n",
    "x0 = np.array([-1.8, 1.3])\n",
    "\n",
    "# Método de Newton\n",
    "x_min_newton = newton_method(f, grad_f, hess_f, x0, tol=1e-6, maxiter=100)\n",
    "print(\"Método de Newton:\")\n",
    "print(\"Punto mínimo:\", x_min_newton)\n",
    "print(\"Valor mínimo:\", f(x_min_newton))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6242b9c-a58b-44e6-a0df-775e83c64a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Punto mínimo: [-0.1085217   2.02341719]\n",
      "Valor mínimo: -2.9108042881360623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2992/3835070628.py:5: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(x[0]**2) + 2*np.exp(x[1]**2)*x[0]**2 + 4*x[0]*x[1] + 2*x[0]**2 + 4*x[0] - 2*x[1]\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
